# Guide: smartspec_production_monitor

## üìö Overview

`/smartspec_production_monitor` is a core workflow for **production operations**. It bridges the gap between your live services and the SmartSpec ecosystem by continuously monitoring health and performance.

**Key Features:**
- ‚úÖ Integrates with observability platforms (Prometheus, Datadog, etc.).
- ‚úÖ Tracks KPIs against NFRs defined in `spec.md`.
- ‚úÖ Generates alerts for SLO breaches.
- ‚úÖ Creates performance reports for the feedback loop.
- ‚úÖ Can run as a one-off check or a continuous daemon.

---

## üéØ Basic Usage

### 1. Run as a Continuous Daemon

```bash
/smartspec_production_monitor --spec-id spec-core-001-authentication --daemon
```

**Behavior (Default):**
- Runs in the background.
- Continuously queries metrics every 60 seconds (configurable).
- Triggers `smartspec_incident_response` if an SLO is breached.
- Generates daily performance reports.

### 2. Run as a One-Off Health Check

```bash
/smartspec_production_monitor --spec-id spec-core-001-authentication --run-once
```

**Behavior:**
- Queries metrics once.
- Prints the current health status to the console.
- Exits.

**Use Cases:**
- Quick health check during a deployment.
- Verifying system status after a rollback.
- Manual check during an incident investigation.

---

## ‚öôÔ∏è Configuration

This workflow relies on two key configuration sources:

### 1. `spec.md` (Non-Functional Requirements)

The workflow reads the NFRs section of your `spec.md` to determine the target SLOs.

```markdown
### Non-Functional Requirements

| Category | Requirement | Metric | Target |
|---|---|---|---|
| Performance | p99 Latency | `api_latency_p99` | < 200ms |
| Reliability | Error Rate | `api_error_rate` | < 0.1% |
| Availability | Uptime | `api_uptime` | > 99.9% |
```

### 2. `observability.yaml`

This file (generated by `smartspec_observability_configurator`) tells the workflow *how* to query the metrics.

```yaml
provider: datadog
api_key: "{{env.DATADOG_API_KEY}}"
metrics:
  - name: api_latency_p99
    query: "avg:trace.rack.request.duration{service:my-api,env:prod}.p99"
  - name: api_error_rate
    query: "sum:trace.rack.request.errors{service:my-api,env:prod}.as_rate()"
```

---

## üí° How It Works

1.  **Load Config:** Reads `spec.md` and `observability.yaml`.
2.  **Query Metrics:** Uses the provider's API to fetch the latest metric values.
3.  **Compare to SLOs:** Compares the fetched values against the targets from the NFRs.
4.  **Alerting:** If a metric is outside its SLO, it triggers `smartspec_incident_response` with a detailed payload.
5.  **Reporting:** Generates daily/weekly reports and triggers `smartspec_feedback_aggregator`.

---

## üö© Flags

- `--spec-id <id>`: **(Required)** The ID of the spec to monitor.
- `--daemon`: Run as a continuous background process.
- `--run-once`: Run once and exit.
- `--interval <seconds>`: (Daemon mode only) The interval between metric queries. Defaults to 60.
