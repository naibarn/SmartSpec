_**Note:** This document explains the concepts behind Golden Testing. For the user manual, please see the [smartspec_validate_golden_tests workflow manual](./validate_golden_tests.md)._

# Knowledge Base: Golden Testing for A2UI Quality Assurance

## 1. The Problem: Ensuring Consistency in AI-Generated UI

As AI models for UI generation become more powerful, they also become less deterministic. The same prompt given to a slightly updated model might produce a different output. While this can lead to creative improvements, it also introduces a significant risk: **regression**. A change in the model or the prompt could inadvertently break a component's layout, violate accessibility standards, or create inconsistencies with the design system.

How can we ensure that our AI-generated UI remains correct, consistent, and compliant over time? The answer is **Golden Testing**.

## 2. What is Golden Testing?

Golden Testing (also known as Snapshot Testing or Approval Testing) is a testing methodology where the output of a system is compared against a previously approved, "golden" version of that output. If the new output matches the golden version, the test passes. If it differs, the test fails, and a human must review the changes.

In the context of SmartSpec, the "output" is the A2UI JSON generated by an AI agent. The "golden version" is a curated A2UI JSON file that has been manually verified as the correct and ideal representation of a specific UI component or layout.

This approach provides a powerful safety net, ensuring that no unintended changes make it into your application.

## 3. The Golden Test Suite in SmartSpec

The SmartSpec golden test suite is a collection of reference files located in the `.spec/golden_tests/` directory. Each file represents a specific test case and is designed to be a comprehensive standard for a particular scenario.

### Anatomy of a Golden Test Case

Each golden test file is a JSON object with two main parts:

1.  **`test_metadata`**: Information about the test itself.
    -   `id`: A unique identifier for the test.
    -   `description`: A human-readable explanation of the test scenario.
    -   `category`: A grouping for related tests (e.g., `forms`, `theming`).
    -   `expected_validity`: Whether the `a2ui_spec` is expected to be `valid` or `invalid`. This is crucial for testing error-handling and ensuring the validator can correctly identify bad output.

2.  **`a2ui_spec`**: The "golden" A2UI v0.8 specification. This is the reference output that the system is tested against.

**Example: A Test Case for an Error Scenario**

```json
{
  "test_metadata": {
    "id": "error_missing_accessibility",
    "description": "Tests that the validator correctly fails a component missing the accessibility object.",
    "category": "errors",
    "expected_validity": "invalid"
  },
  "a2ui_spec": {
    "version": "0.8",
    "type": "component",
    "spec": {
      "type": "image",
      "src": "logo.png"
      // The 'accessibility' object is deliberately missing
    }
  }
}
```

In this example, the test is designed to *fail* validation, confirming that our quality gates are working correctly.

## 4. The Role of `smartspec_validate_golden_tests`

The `smartspec_validate_golden_tests` workflow is the automated process that runs these checks. It iterates through the golden test suite and performs a deep validation on the `a2ui_spec` portion of each file.

### The Validation Process

The validator performs several layers of checks:

1.  **Schema Compliance:** Ensures the JSON adheres to the official A2UI v0.8 schema.
2.  **Structural Integrity:** Verifies that components are correctly structured (e.g., form fields are inside a form).
3.  **Accessibility Rules:** Enforces best practices, such as requiring `alt` text for images and `aria-label` for interactive elements.
4.  **Theming Validation:** Checks that all theme token references (e.g., `{colors.primary.500}`) point to valid tokens defined in `theme.json`.

If the validation result matches the `expected_validity` in the metadata, the test passes. For instance, if a test is expected to be `invalid` and the validator correctly identifies it as invalid, the test passes.

## 5. Benefits of Golden Testing

- **Automated Regression Prevention:** Provides an automated safety net to catch unintended changes before they reach production.
- **Enforces Quality and Consistency:** Acts as a "linting" tool for your A2UI output, enforcing best practices in accessibility, theming, and structure.
- **Living Documentation:** The golden test suite serves as a form of living documentation, providing clear, working examples of how to correctly structure various UI components.
- **Confidence in Refactoring:** Allows you to refactor prompts or update the AI model with confidence, knowing that the test suite will catch any regressions.
- **CI/CD Integration:** With support for JUnit XML output, golden tests can be seamlessly integrated into your CI/CD pipeline, acting as a quality gate that prevents broken UI from being deployed.

## 6. Best Practices

- **Start with the Core Set:** Begin with the comprehensive set of golden tests provided with SmartSpec. These cover the most common components and scenarios.
- **Create Tests for Your Custom Components:** As you build custom or complex components, create corresponding golden tests to ensure they remain stable.
- **Test Both Success and Failure:** Create tests for both valid and invalid output. Testing that your validator correctly identifies errors is just as important as testing for valid output.
- **Integrate into Your Workflow:** Run the validation workflow as a pre-commit hook or as a required check in your CI pipeline to get the most benefit.
- **Review Failures Carefully:** When a test fails, it means either a regression has occurred (which needs to be fixed) or the golden standard itself needs to be updated. This review process is a critical part of maintaining the test suite's integrity.

By incorporating golden testing into your A2UI development process, you are building a robust, self-validating system that ensures high quality and consistency, even as your application and the underlying AI models evolve.
