| manual_name | manual_version | compatible_workflow | compatible_workflow_versions | role |
| --- | --- | --- | --- | --- |
| /smartspec_ui_validation Manual (EN) | 5.6 | /smartspec_ui_validation | 5.6.2 – 5.6.x | user/operator manual (frontend, QA, UX, release, platform) |

# /smartspec_ui_validation Manual (v5.6, English)

## 1. Overview

This manual explains how to use the workflow:

> `/smartspec_ui_validation v5.6.x` (e.g., 5.6.2, 5.6.3, 5.6.4)

The workflow is a **governance layer for UI correctness & validation**.
It focuses on:

- checking that implemented UI **matches specs / UI JSON / UX flows**
- assessing how well UI has been **validated** across:
  - behavior and flows (happy paths + edge cases)
  - error states and input validation
  - accessibility (a11y)
  - visual regression / snapshot testing
  - internationalization (i18n) / localization
  - cross-environment / cross-device combinations
- producing a **UI validation report** per UI unit (route/screen/flow)
  with status fields and `blocking_for_release` signals
- from v5.6.3 onwards, also reading **AI-generated `ui.json` metadata**
  (origin, review status, design system version, style preset) to
  understand how much you can trust each UI spec
- from v5.6.4, incorporating **security & dependency evidence**
  (especially for React/Next.js/RSC, Node/npm) and **design-system &
  component registry context** into the risk model (without adding new
  flags or changing NO-WRITE behavior)

> **Important:**
> - The workflow does **not** run tests or launch browsers/devices.
> - It does **not** modify code, configs, or test files.
> - It only reads existing artifacts (specs, UI JSON, test reports,
>   security/dependency reports, registries) and synthesizes a
>   governance view.

### 1.1 Why you need this workflow

Without a structured UI validation governance layer, teams often face:

- critical flows that are assumed to be tested but lack any real
  coverage
- missing tests for edge cases and error/validation states
- a11y reports existing somewhere in CI, but no clear connection to
  specific flows/screens
- visual regression tests with unclear mapping to business-critical
  screens
- i18n gaps where important locales are not adequately validated
- release boards seeing only a "tests passed" percentage in CI, with no
  mapping back to UI specs or flows
- in systems where `ui.json` is generated by AI by default:
  - some flows use AI-written specs that no human has ever reviewed
  - you have no structured way to see which flows rely most on
    unreviewed AI specs
- in modern web stacks (React/Next.js/RSC) with fast-moving
  dependencies:
  - security/SCA reports exist but are not connected to specific
    critical UI flows
  - React Server Components or `react-server-dom-*` are used without
    clear governance on patched versions and data-leakage risks

`/smartspec_ui_validation` connects:

> **spec / UI JSON (including AI-generated) ↔ implementation ↔ test & security reports**

into a single report that answers:

> "Before this release, how well have our critical UI flows been
> validated, and where are the gaps?"  
> and  
> "Where are we relying on unreviewed AI-generated `ui.json` or
> missing security/dependency evidence for flows that really matter?"

### 1.2 Benefits of using it

- Provides a **shared language** for frontend, QA, UX, security, and
  release stakeholders.
- Shows **validation status per UI unit** in a structured way.
- Makes it clear, per flow, whether:
  - the spec/UI JSON comes from AI vs humans
  - the spec has been reviewed
  - the `ui.json` structure looks strong or weak
  - there is clear security/dependency evidence for web UI stacks
- Helps release boards decide:
  - which flows are ready
  - which flows need additional tests or security work
  - where risk is accepted with clear rationale
- Produces an **audit artifact** that shows UI validation (including
  AI-spec trust, a11y, i18n, and security evidence) was reviewed before
  release.

### 1.3 Risks if you don’t use it (or equivalent governance)

- Releasing critical flows (login/checkout/consent) with no real test
  coverage.
- Shipping blocking accessibility issues unnoticed.
- i18n bugs discovered late in production because locales were not
  validated systematically.
- Relying on AI-generated `ui.json` as the source of truth without any
  visibility into which flows are still unreviewed.
- No clear artifact that shows which screens/flows passed validation,
  making management/auditor conversations harder.
- For React/Next.js/RSC stacks, shipping critical flows while:
  - using outdated or vulnerable dependencies,
  - lacking any clear SCA/lockfile/registry evidence,
  - or having unreviewed RSC/`react-server-dom-*` usage in
    high-criticality UI.

---

## 2. What’s New in v5.6

### 2.1 Per-UI-unit status model

Each UI unit now has a consistent status model including:

- `criticality = CRITICAL | HIGH | MEDIUM | LOW | UNKNOWN`
- `spec_coverage_status = FULL | PARTIAL | NONE | UNKNOWN`
- `behavior_validation_status = STRONG | BASIC | NONE | UNKNOWN`
- `error_state_coverage_status = COMPREHENSIVE | PARTIAL | NONE | UNKNOWN`
- `input_validation_coverage_status = COMPREHENSIVE | PARTIAL | NONE | UNKNOWN`
- `accessibility_status = GOOD | ISSUES_NON_BLOCKING | ISSUES_BLOCKING | UNKNOWN`
- `visual_regression_status = COVERED | PARTIAL | NONE | UNKNOWN`
- `i18n_status = COVERED | PARTIAL | NONE | UNKNOWN`
- `cross_env_status = COVERED | PARTIAL | NONE | UNKNOWN`
- `risk_level = LOW | MEDIUM | HIGH | CRITICAL`
- `blocking_for_release = true | false`

### 2.2 Clear strict-mode rules

In `--safety-mode=strict`:

- for units with `criticality in {CRITICAL, HIGH}`:
  - missing/unknown behavior validation or spec coverage → blocking
  - `accessibility_status=ISSUES_BLOCKING` → blocking
  - `visual_regression_status=NONE/UNKNOWN` for visually critical units →
    usually blocking
  - `i18n_status=NONE/UNKNOWN` for required locales → usually blocking
  - `cross_env_status=PARTIAL/NONE` where multiple envs/devices are
    required → affects risk and may be blocking

### 2.3 Criticality derivation

Criticality is derived from:

- registries (e.g., `.spec/registry/*` that mark critical flows)
- tags in specs / UI JSON (e.g., `critical: true`, `importance: "high"`)
- explicit overrides via `--ui-critical-targets`

If nothing is defined, units default to `MEDIUM` or `LOW` with a note
that criticality is uncertain.

### 2.4 Relationship with release readiness

- The report produces `blocking_for_release` as an **additional
  governance signal** for `/smartspec_release_readiness` and other
  workflows.
- It does not override other workflows, but `blocking` items should be
  explicitly discussed and resolved (or formally risk-accepted) by the
  release decision-makers.

### 2.5 AI-generated `ui.json` signals (added in v5.6.3)

From v5.6.3 onwards, each UI unit also includes signals about
AI-generated `ui.json` quality and trustworthiness:

- `ui_spec_origin = AI | HUMAN | MIXED | UNKNOWN`
  - indicates whether the spec/UI JSON is primarily AI-generated,
    human-authored, or mixed.
- `ui_spec_review_status = UNREVIEWED | DESIGNER_APPROVED | OVERRIDDEN | UNKNOWN`
  - derived from `meta.review_status` or registries; shows whether the
    spec has been reviewed.
- `ui_json_quality_status = STRONG | OK | WEAK | BROKEN | UNKNOWN`
  - summarizes how coherent and complete the `ui.json` is relative to
    the design system and flows.

A new flag is introduced:

- `--ui-json-ai-strict`
  - enables stricter rules for AI-generated UI JSON.
  - when a flow is critical/high and `ui_spec_origin=AI` with
    `ui_spec_review_status=UNREVIEWED` or `ui_json_quality_status` is
    low, risk is raised and may become `blocking_for_release` in strict
    mode.

### 2.6 v5.6.4: Security & design-system clarifications

v5.6.4 does **not** add new flags or change any existing CLI semantics.
It adds governance clarifications so that the workflow:

- reads **security & dependency evidence** for UI-facing web stacks
  (React/Next.js/RSC, Node/npm) where available (e.g., SCA reports,
  `tool-version-registry.json`, CI security gate summaries, lockfiles),
  and reflects missing/outdated evidence as part of `risk_level` and
  `blocking_for_release`, especially for critical/high units in strict
  mode.
- treats RSC / `react-server-dom-*` usage as a **high-risk surface**
  that needs clear patch-level and data-leakage governance before
  critical flows are considered safe.
- uses **design-system & component registries** as context rather than
  pure style enforcement, e.g.:
  - preferring `AppButton`/`AppCard` over raw library components in
    critical flows,
  - checking that required layout/pattern states (loading/empty/error)
    are actually validated.

All changes are **additive** and fully backward compatible with
v5.6.2–v5.6.3.

---

## 3. Backward Compatibility Notes

- This v5.6 manual targets `/smartspec_ui_validation` from
  **v5.6.2 onwards**, including **v5.6.4**.
- `--strict` remains an alias for `--safety-mode=strict`.
- v5.6.3 adds `--ui-json-ai-strict` and AI-related signals
  (`ui_spec_origin`, `ui_spec_review_status`, `ui_json_quality_status`)
  in an additive way.
- v5.6.4 adds **security/dependency** and **design-system** clarifications
  without changing flags or NO-WRITE guarantees.

---

## 4. Core Concepts

### 4.1 What is a UI unit?

A UI unit is typically one of:

- a route (e.g., `/checkout`, `/login`)
- a screen/page (e.g., "Profile Screen")
- a user flow (e.g., "Checkout Flow", "Password Reset Flow")

Each unit receives a status record using the fields listed above.

### 4.2 Criticality

Criticality reflects how important a UI unit is, e.g.:

- CRITICAL
  - login, checkout, payment, consent, account recovery
  - flows with regulatory or strong legal impact
- HIGH
  - flows with strong conversion or business impact
- MEDIUM / LOW
  - less critical but still relevant flows

Criticality comes from:

- registries (critical flows, SLOs)
- spec / UI JSON tags
- explicit `--ui-critical-targets`

### 4.3 Signals from AI-generated `ui.json`

For systems where AI generates `ui.json` by default, each UI unit also
has:

- `ui_spec_origin` → source of the spec (AI vs human vs mixed)
- `ui_spec_review_status` → whether the spec was reviewed
- `ui_json_quality_status` → structural quality of `ui.json`

These signals are combined with other statuses to compute `risk_level`
and `blocking_for_release`, especially in strict mode and when
`--ui-json-ai-strict` is enabled.

### 4.4 Governance-only scope

This workflow does **not**:

- run cypress/playwright/jest or similar tools
- create or modify test files
- output ready-to-run test commands as implicitly "approved"

It only reads specs/UI JSON + test & security reports and produces a
governance summary.

---

## 5. Quick Start Examples

### 5.1 Validate checkout UI (web)

```bash
smartspec_ui_validation \
  --spec-ids=checkout_service \
  --run-label=checkout-ui-pre-release \
  --ui-spec-paths=".spec/ui/**/*.json" \
  --ui-test-report-paths=".reports/ui/e2e/**/*.json" \
  --ui-snapshot-report-paths=".reports/ui/snapshot/**/*.json" \
  --ui-accessibility-report-paths=".reports/ui/a11y/**/*.json" \
  --ui-i18n-report-paths=".reports/ui/i18n/**/*.json" \
  --target-envs=web \
  --target-browsers=chromium,firefox \
  --report-format=md \
  --stdout-summary
```

### 5.2 Strict mode for login + consent flows with strict AI UI JSON

```bash
smartspec_ui_validation \
  --spec-ids=identity_service \
  --run-label=login-consent-ui-strict \
  --ui-critical-targets=login,consent_flow \
  --ui-spec-paths=".spec/ui/**/*.json" \
  --ui-test-report-paths=".reports/ui/e2e/**/*.json" \
  --ui-accessibility-report-paths=".reports/ui/a11y/**/*.json" \
  --target-envs=web \
  --target-browsers=chromium,firefox,safari \
  --safety-mode=strict \
  --ui-json-ai-strict \
  --report-format=json \
  --stdout-summary
```

### 5.3 Inline UI project (no UI JSON)

```bash
smartspec_ui_validation \
  --spec-ids=legacy_portal \
  --run-label=legacy-portal-ui-validation \
  --ui-json-mode=disabled \
  --ui-spec-paths="specs/ui/**/*.md" \
  --ui-test-report-paths=".reports/ui/e2e/**/*.json" \
  --report-format=md
```

---

## 6. CLI / Flags Cheat Sheet

- Scope & label
  - `--spec-ids`
  - `--ui-targets`
  - `--ui-critical-targets`
  - `--include-dependencies`
  - `--run-label`
- UI spec & implementation
  - `--ui-spec-paths`
  - `--ui-impl-paths`
  - `--ui-json-mode=auto|required|disabled`
  - `--ui-json-ai-strict` (tighten rules for AI-generated `ui.json`)
- Test & report artifacts
  - `--ui-test-report-paths`
  - `--ui-snapshot-report-paths`
  - `--ui-accessibility-report-paths`
  - `--ui-i18n-report-paths`
- Environment & platform
  - `--target-envs`
  - `--target-browsers`
  - `--target-devices`
- Multi-repo & safety
  - `--workspace-roots`
  - `--repos-config`
  - `--registry-dir`, `--registry-roots`
  - `--index`, `--specindex`
  - `--safety-mode=normal|strict` (`--strict`)
- Output & KiloCode
  - `--report-format=md|json`
  - `--report-dir`
  - `--stdout-summary`
  - `--kilocode`, `--nosubtasks`

---

## 7. Reading the UI Validation Report

Typical structure:

1. **Scope overview**
   - spec-ids, environments, browsers, devices
   - date, run-label

2. **Per-UI-unit table**
   - for each `unit_id`:
     - `criticality`
     - `ui_spec_origin`
     - `ui_spec_review_status`
     - `ui_json_quality_status`
     - `spec_coverage_status`
     - `behavior_validation_status`
     - `error_state_coverage_status`
     - `input_validation_coverage_status`
     - `accessibility_status`
     - `visual_regression_status`
     - `i18n_status`
     - `cross_env_status`
     - `risk_level`
     - `blocking_for_release`
     - `notes`

3. **Gaps & risks**
   - highlighted units with `risk_level=HIGH/CRITICAL` or
     `blocking_for_release=true`
   - special attention to units where:
     - `ui_spec_origin=AI` and `ui_spec_review_status=UNREVIEWED`
     - `ui_json_quality_status=WEAK/BROKEN`
     - security/dependency evidence is missing or clearly outdated for
       a React/Next.js/RSC UI

4. **Summary**
   - counts by risk level
   - counts by blocking vs non-blocking

> Note: When `--report-format=json`, JSON is the canonical structure.
> The markdown report should mirror the same fields to support tooling.

---

## 8. KiloCode Usage Examples

### 8.1 Kilo for web + mobile apps

```bash
smartspec_ui_validation \
  --spec-ids=mobile_app,web_portal \
  --include-dependencies \
  --run-label=web-mobile-ui-validation \
  --ui-spec-paths=".spec/ui/**/*.json" \
  --ui-test-report-paths=".reports/ui/e2e/**/*.json" \
  --ui-accessibility-report-paths=".reports/ui/a11y/**/*.json" \
  --target-envs=web,ios,android \
  --kilocode \
  --stdout-summary
```

On Kilo:

- Orchestrator decomposes work by spec-id/flow group.
- Code mode reads reports read-only.
- Results are aggregated per-unit in the final report.

### 8.2 Disabling subtasks for a small scope

```bash
smartspec_ui_validation \
  --spec-ids=small_widget_service \
  --run-label=small-widget-ui-validation \
  --ui-spec-paths=".spec/ui/small_widget/*.json" \
  --ui-test-report-paths=".reports/ui/e2e/small_widget/**/*.json" \
  --kilocode \
  --nosubtasks
```

---

## 9. Multi-repo / Multi-registry Examples

### 9.1 Monorepo with multiple frontend apps

```bash
smartspec_ui_validation \
  --spec-ids=web_portal,admin_portal \
  --run-label=portal-ui-validation \
  --repos-config=.spec/repos.yaml \
  --registry-dir=.spec/registry \
  --ui-spec-paths=".spec/ui/**/*.json" \
  --ui-test-report-paths=".reports/ui/e2e/**/*.json" \
  --report-format=md
```

### 9.2 Multi-repo, multi-team

```bash
smartspec_ui_validation \
  --spec-ids=teamA_web,teamB_mobile \
  --run-label=web-mobile-crossflow-validation \
  --workspace-roots="../teamA;../teamB" \
  --registry-dir=../platform/.spec/registry \
  --ui-spec-paths="../teamA/.spec/ui/**/*.json;../teamB/.spec/ui/**/*.json" \
  --ui-test-report-paths="../teamA/.reports/ui/e2e/**/*.json;../teamB/.reports/ui/e2e/**/*.json"
```

---

## 10. UI JSON vs Inline UI

### 10.1 JSON-first UI

- Screens/flows are defined in files such as:
  - `.spec/ui/<app>.ui.json` or similar.
- The workflow treats UI JSON as the **primary source of truth**.
- When `--ui-json-mode=required` and UI JSON is missing:
  - this is treated as a validation gap for
    `spec_coverage_status` and `ui_json_quality_status`.
- For AI-generated UI JSON it is strongly recommended to always
  populate meta fields:
  - `source`, `generator`, `design_system_version`, `style_preset`,
    `review_status`.

### 10.2 Inline UI / opt-out

- No separate UI JSON; specs are in markdown/docs.
- Use `--ui-json-mode=disabled`.
- The workflow still builds a report from specs + test reports.

---

## 11. Benefits vs Risks of Not Using

### 11.1 Benefits of using

- Clear visibility into how thoroughly UI has been validated per
  flow/screen.
- Clarity about how much each flow depends on AI-generated `ui.json`,
  and whether it has been reviewed.
- Better release meeting discussions: not just "tests passed X%" but
  "these critical flows are covered at level Y with AI UI JSON quality
  Z and security evidence E".
- Easier prioritization of work on tests, a11y, i18n, and
  dependency/security improvements.

### 11.2 Risks if you don’t use it

- Shipping critical flows with poor or unknown validation coverage.
- Shipping flows where `ui.json` is AI-generated and still
  `UNREVIEWED`.
- Building silent UX/a11y/i18n technical debt.
- Lacking evidence that UI correctness and security posture were
  reviewed before releases.

---

## 12. FAQ / Troubleshooting

**Q1: What if we have almost no UI tests or reports?**  
The workflow can still run but will mark many statuses as
`NONE`/`UNKNOWN`. That is a strong signal to invest in UI tests before
major releases, especially for critical flows.

**Q2: Will the workflow fix code or generate tests for us?**  
No. It only indicates where validation gaps are. You can use other
prompt/workflow patterns for test generation if desired.

**Q3: Should we always use strict mode?**  
Not always. Use `strict` for flows with high `criticality` (login,
checkout, payments, consent, identity, etc.), especially when
`ui.json` is AI-generated and still `UNREVIEWED`.

**Q4: Does this workflow replace security tools or SCA?**  
No. It reads existing security/dependency reports and registries
(where present) and folds them into the risk picture for UI units. You
still need dedicated security workflows and CI gates.

---

## 13. Security & Dependency Notes (Web/React/Next.js/RSC)

This section summarizes how `/smartspec_ui_validation` interacts with
modern web-stack security and dependency governance, as clarified in
v5.6.4.

- The workflow **never runs** security tools itself (no `npm audit`,
  no test runners). It only reads existing artifacts.
- When a UI implementation uses React/Next.js/RSC or similar stacks
  (as inferred from specs, registries, or reports), the workflow:
  - treats **RSC / `react-server-dom-*`** as a high-risk surface that
    should have clear patch baselines and data-leakage reviews,
    especially for CRITICAL/HIGH units.
  - looks for evidence such as:
    - SCA/vulnerability reports,
    - dependency snapshots/lockfile summaries,
    - CI security gate reports,
    - a central `tool-version-registry.json` for React/Next.js/Node.
  - if such evidence is missing or clearly outdated for
    CRITICAL/HIGH UI units, this may:
    - raise `risk_level`, and
    - set `blocking_for_release=true` in strict mode (with an
      explanation in `notes`).
- The workflow separates **UI correctness** from **dependency safety**
  but allows you to see them together in the same per-unit report.

**Best practice:** run this workflow alongside your standard
security/SCA pipelines so that release boards see a combined picture:
UI validation + security evidence by flow.

---

## 14. Design-System & Component Registry Notes

v5.6.4 also clarifies how the workflow uses design systems and
component registries as governance context:

- When registries such as `design-tokens-registry.json`,
  `ui-component-registry.json`, `app-component-registry.json`, or
  `patterns-registry.json` exist in `.spec/registry/`:
  - the workflow treats them as inputs describing **intended UI
    structure and components**, not as mere style suggestions.
  - it does *not* validate colors/spacing directly (that remains a
    job for UI consistency/audit workflows), but it:
    - prefers App-level components (`AppButton`, `AppCard`, etc.) over
      raw UI library components for critical flows, where the registry
      indicates such usage.
    - calls out in `notes` when CRITICAL/HIGH units apparently rely
      heavily on raw UI library components instead of App-level wrappers.
- For flows covered by layout/pattern registries (e.g. workspace
  layouts, AI run viewers, standardized empty/loading/error states):
  - missing tests for key states in those patterns should reduce
    `error_state_coverage_status` and increase `risk_level`.

**Takeaway:** this workflow treats your design system and component
registries as part of the **governance surface** around UI validation;
use it together with UI consistency workflows to keep both behavior and
visual language aligned.

---

End of `/smartspec_ui_validation v5.6.x` manual (English), updated for
workflow v5.6.4.
